{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbd32dc-ed65-4f5a-b1d8-be620c78089c",
   "metadata": {},
   "source": [
    "# PCAI Use Case Demo - Serving LoRa in MLIS\n",
    "In this tutorial, we will deploy LoRa Adapter with vLLM in MLIS. Additionally, we will leverage aioli-sdk to programatically deploy the model in MLIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79724053-ed09-4fcd-9514-549ba75cd943",
   "metadata": {},
   "source": [
    "**1. Install Required Libraries**</br>\n",
    "Before running the demo, please install the necessary libraries in your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7864cc1f-b054-4b78-8d11-56b083a52fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aioli-sdk==1.4.1\n",
      "  Using cached aioli_sdk-1.4.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (24.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (1.26.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=18.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (26.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (3.20.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (2.32.3)\n",
      "Requirement already satisfied: lomond>=0.3.3 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (0.3.3)\n",
      "Requirement already satisfied: pathspec>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (0.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (3.2.0)\n",
      "Requirement already satisfied: argcomplete>=1.9.4 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (3.6.3)\n",
      "Requirement already satisfied: gitpython>=3.1.3 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (3.1.44)\n",
      "Requirement already satisfied: pyOpenSSL>=19.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (25.3.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (2025.2)\n",
      "Requirement already satisfied: tabulate>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (0.9.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.15.29 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (0.18.10)\n",
      "Requirement already satisfied: docker>=3.7.3 in /opt/conda/lib/python3.11/site-packages (from docker[ssh]>=3.7.3->aioli-sdk==1.4.1) (7.1.0)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (4.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (4.67.1)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (1.4.4)\n",
      "Requirement already satisfied: analytics-python in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (1.4.post1)\n",
      "Requirement already satisfied: urllib3<2.3.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (2.2.3)\n",
      "Requirement already satisfied: pydantic>=2 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7.1 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (4.13.1)\n",
      "Requirement already satisfied: pytest>=7.4.4 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (9.0.1)\n",
      "Requirement already satisfied: pytest-cov>=4.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (7.0.0)\n",
      "Requirement already satisfied: pexpect>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.4.1) (4.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython>=3.1.3->aioli-sdk==1.4.1) (4.0.12)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from lomond>=0.3.3->aioli-sdk==1.4.1) (1.17.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.4.1) (5.0.0)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.4.1) (46.0.3)\n",
      "Requirement already satisfied: invoke>=2.0 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.4.1) (2.2.1)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.4.1) (1.6.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>=4.9.0->aioli-sdk==1.4.1) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2->aioli-sdk==1.4.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2->aioli-sdk==1.4.1) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2->aioli-sdk==1.4.1) (0.4.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from pytest>=7.4.4->aioli-sdk==1.4.1) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.11/site-packages (from pytest>=7.4.4->aioli-sdk==1.4.1) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /opt/conda/lib/python3.11/site-packages (from pytest>=7.4.4->aioli-sdk==1.4.1) (2.19.1)\n",
      "Requirement already satisfied: coverage>=7.10.6 in /opt/conda/lib/python3.11/site-packages (from coverage[toml]>=7.10.6->pytest-cov>=4.1.0->aioli-sdk==1.4.1) (7.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->aioli-sdk==1.4.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->aioli-sdk==1.4.1) (3.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.11/site-packages (from ruamel.yaml>=0.15.29->aioli-sdk==1.4.1) (0.2.8)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.11/site-packages (from analytics-python->aioli-sdk==1.4.1) (1.6)\n",
      "Requirement already satisfied: backoff==1.10.0 in /opt/conda/lib/python3.11/site-packages (from analytics-python->aioli-sdk==1.4.1) (1.10.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.3->paramiko>=2.4.2->aioli-sdk==1.4.1) (2.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.3->aioli-sdk==1.4.1) (5.0.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=3.3->paramiko>=2.4.2->aioli-sdk==1.4.1) (2.22)\n",
      "Using cached aioli_sdk-1.4.1-py3-none-any.whl (170 kB)\n",
      "Installing collected packages: aioli-sdk\n",
      "  Attempting uninstall: aioli-sdk\n",
      "    Found existing installation: aioli-sdk 1.10.0\n",
      "    Uninstalling aioli-sdk-1.10.0:\n",
      "      Successfully uninstalled aioli-sdk-1.10.0\n",
      "Successfully installed aioli-sdk-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install aioli-sdk==1.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c4a0a-c2b6-40da-9100-49450f9080cd",
   "metadata": {},
   "source": [
    "# Intialize API client for MLIS's rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62b6f34-a01f-4157-9861-76ad75ba4163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token successfully refreshed.\n"
     ]
    }
   ],
   "source": [
    "%update_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca9d23b-c70d-461a-b1aa-20cbfdd2c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = os.popen(\"kubectl get pvc user-pvc -o=jsonpath='{.metadata.namespace}'\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96119976-ef2a-4562-b363-ed10cc7ea8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiolirest\n",
    "from aioli.common import util\n",
    "from aioli.common.api import authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb44a94-9483-455b-bbe3-1c8bb9774d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_url = \"http://aioli-master-service-hpe-mlis.mlis.svc.cluster.local:8080\"\n",
    "\n",
    "host = util.prepend_protocol(host_url)\n",
    "with open('/etc/secrets/ezua/.auth_token','r') as f:\n",
    "    token = f.read()\n",
    "# token = util.get_aioli_user_token_from_env()\n",
    "configuration = authentication.get_rest_config(host)\n",
    "configuration.api_key[\"ApiKeyAuth\"] = \"Bearer \" + token\n",
    "restclient = aiolirest.ApiClient(configuration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4cfaebc-9d76-4b71-b121-cadb6f552496",
   "metadata": {},
   "source": [
    "# Create Registry\n",
    "In MLIS, Registries are the storage location of the models. User can ADD/EDIT/LIST/DELETE Registry\n",
    "**Available Registry Types**\n",
    "- S3 : S3 bucket and necessary Access keys needed\n",
    "- Huggingface or OpenLLM : Sign up for a HuggingFace and create an access token\n",
    "- NGC : Sign up for an NVIDIA NGC Account and obtain the necessary API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845d1cff-cec8-4889-9627-2c792fdd9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = aiolirest.RegistriesApi(restclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c65bf3e-317d-4591-967c-e8468b3833bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found endpoint for s3 via: environment_global.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow.sgctcpcai\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3 = boto3.client(\"s3\", verify=False)\n",
    "buckets = s3.list_buckets()\n",
    "for bucket in buckets['Buckets']:\n",
    "    if 'mlflow' in bucket['Name']:\n",
    "      bucket_name = bucket['Name']\n",
    "\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbed04e2-dd99-4c71-bfbd-b2264d0779ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiolirest.models.trained_model_registry_request import TrainedModelRegistryRequest\n",
    "\n",
    "r = TrainedModelRegistryRequest(\n",
    "    name='s3-bucket-from-sdk',\n",
    "    bucket=bucket_name,\n",
    "    endpointUrl='http://local-s3-service.ezdata-system.svc.cluster.local:30000',\n",
    "    type='s3',\n",
    "    accessKey=token,\n",
    "    secretKey='s3',\n",
    "    insecureHttps=False,\n",
    ")\n",
    "registry_request = api_instance.registries_post(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926b828-bc59-460e-b614-3e57faf7dfd8",
   "metadata": {},
   "source": [
    "<img src=\"./assets/mlis_registry_aie180.png\" alt=\"mlis_registry_1\" width=\"400\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a9a2cd-fbb5-4af5-a33b-538fe9c87247",
   "metadata": {},
   "source": [
    "# Create Packaged Model\n",
    "In MLIS, A packaged Model describes the model that user want to deploy as an inference service.\n",
    "By Adding a packaged model, user can create a versioned pointer to a model stored in a specified registry and PVC. \n",
    "Access to reading and pulling is controlled by the registry’s assigned keys\n",
    "\n",
    "**Available Model Types**\n",
    "- Bento Archive : S3\n",
    "- Custom : OpenLLM, PVC, S3, None\n",
    "- NIM : NGC, PVC\n",
    "- OpenLLM : OpenLLM, S3\n",
    "- vLLM : HuggingFace, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0670439a-3486-4d82-9a26-2ce8b5dc42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiolirest.models.configuration_resources import ConfigurationResources\n",
    "from aiolirest.models.packaged_model_request import PackagedModelRequest\n",
    "from aiolirest.models.resource_profile import ResourceProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d1690d-dc2e-4192-a0d5-9e64834624cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = aiolirest.PackagedModelsApi(restclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dc1d328-1458-46ca-a47a-8cf5663cbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "full_model_name = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "\n",
    "config = {\n",
    "    'requests_cpu': '1',\n",
    "    'requests_gpu': '1',\n",
    "    'requests_memory': '4Gi',\n",
    "    'limits_cpu': '4',\n",
    "    'limits_gpu': '1',\n",
    "    'limits_memory': '8Gi',\n",
    "    'enable_caching': False,\n",
    "    'disable_caching': False,\n",
    "    'metadata': {\n",
    "        'modelCategory=llm'\n",
    "    },\n",
    "    'env': {},\n",
    "    'arg': [\n",
    "        '--model',\n",
    "        full_model_name,\n",
    "        '--port',\n",
    "        '8080',\n",
    "        '--dtype=half',\n",
    "        '--gpu-memory-utilization',\n",
    "        '0.8',\n",
    "        '--enable-lora',\n",
    "        '--lora-modules',\n",
    "        '{\"name\":\"math-lora\",\"path\":\"/mnt/models\",\"base_model_name\":\"' + full_model_name + '\"}',\n",
    "    ]\n",
    "}\n",
    "args = Namespace(**config)\n",
    "requests = ResourceProfile(\n",
    "    cpu=args.requests_cpu, gpu=args.requests_gpu, memory=args.requests_memory\n",
    ")\n",
    "limits = ResourceProfile(\n",
    "    cpu=args.limits_cpu, gpu=args.limits_gpu, memory=args.limits_memory\n",
    ")\n",
    "resources = ConfigurationResources(gpuType=None, requests=requests, limits=limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07c3a372-8b8b-4f19-9cd0-22d68bf9358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelCategory': 'llm'}\n",
      "{}\n",
      "['--model', 'HuggingFaceTB/SmolLM2-360M-Instruct', '--port', '8080', '--dtype=half', '--gpu-memory-utilization', '0.8', '--enable-lora', '--lora-modules', '{\"name\":\"math-lora\",\"path\":\"/mnt/models\",\"base_model_name\":\"HuggingFaceTB/SmolLM2-360M-Instruct\"}']\n"
     ]
    }
   ],
   "source": [
    "from aioli.common.util import (\n",
    "    construct_arguments,\n",
    "    construct_environment,\n",
    "    construct_metadata,\n",
    ")\n",
    "print(construct_metadata(args, {}))\n",
    "print(construct_environment(args))\n",
    "print(construct_arguments(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089d7801-f0ab-41fc-b2ab-030cab6c2d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact URI: s3://mlflow.sgctcpcai/0/474dfdce2c9340388d1fa30a2b5bad6c/artifacts\n",
      "Full artifact URI: s3://mlflow.sgctcpcai/0/474dfdce2c9340388d1fa30a2b5bad6c/artifacts/math-SmolLM2-360M-Instruct-savedir/peft\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Get the experiment ID\n",
    "experiment_name = \"Default\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "latest_run = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "artifact_uri = latest_run.artifact_uri[0]\n",
    "print(f\"Artifact URI: {artifact_uri}\")\n",
    "\n",
    "# For a specific artifact file/folder\n",
    "artifact_path = 'math-SmolLM2-360M-Instruct-savedir/peft'  # or any artifact path\n",
    "\n",
    "full_artifact_uri = f\"{artifact_uri}/{artifact_path}\"\n",
    "print(f\"Full artifact URI: {full_artifact_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8d5f817-661a-4c80-8062-d7036db1d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = PackagedModelRequest(\n",
    "    name='packaged-model-from-sdk',\n",
    "    description='packaged-model-from-sdk',\n",
    "    url=full_artifact_uri,\n",
    "    # url='s3://mlflow.sgctcpcai/0/474dfdce2c9340388d1fa30a2b5bad6c/artifacts/math-SmolLM2-360M-Instruct-savedir/peft',\n",
    "    image='vllm/vllm-openai:v0.8.5',\n",
    "    resources=resources,\n",
    "    modelFormat='custom',\n",
    "    arguments=construct_arguments(args),\n",
    "    metadata=construct_metadata(args, {}),\n",
    "    registry=registry_request.name,\n",
    ")\n",
    "\n",
    "if args.enable_caching:\n",
    "    r.caching_enabled = True\n",
    "\n",
    "if args.disable_caching:\n",
    "    r.caching_enabled = False\n",
    "\n",
    "resposne = api_instance.models_post(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa5b4a13-84bb-4912-813c-402404c34b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackagedModel(arguments=['--model', 'HuggingFaceTB/SmolLM2-360M-Instruct', '--port', '8080', '--dtype=half', '--gpu-memory-utilization', '0.8', '--enable-lora', '--lora-modules', '{\"name\":\"math-lora\",\"path\":\"/mnt/models\",\"base_model_name\":\"HuggingFaceTB/SmolLM2-360M-Instruct\"}'], caching_enabled=False, description='packaged-model-from-sdk', environment={}, id='15c0b7a3-062a-4959-ae6c-8f3321bd24b2', image='vllm/vllm-openai:v0.8.5', metadata={'modelCategory': 'llm'}, format='custom', modified_at='2025-11-14T14:59:42.355809Z', name='packaged-model-from-sdk', project='69fc1dd6-47eb-4411-9d75-dc24d94db622', registry='f81459fb-b317-4169-8cdd-3a89de355e1c', resources=ConfigurationResources(gpu_type='', limits=ResourceProfile(cpu='4', gpu='1', memory='8Gi'), requests=ResourceProfile(cpu='1', gpu='1', memory='4Gi')), url='s3://mlflow.sgctcpcai/0/474dfdce2c9340388d1fa30a2b5bad6c/artifacts/math-SmolLM2-360M-Instruct-savedir/peft', version=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75266c-4d7d-47ea-bcb7-e61a0d1b1e6c",
   "metadata": {},
   "source": [
    "<img src=\"./assets/mlis_packaged_aie180.png\" alt=\"mlis_packaged_1\" width=\"400\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a9b4888-121e-4923-9e05-b8a3b148b402",
   "metadata": {},
   "source": [
    "# Deploy Model\n",
    "In MLIS, Deployments spin up the actual instances that run user’s inference services. \n",
    "\n",
    "As a result of deployment, it will provide an endpoint that can be used by clients to make predictions.\n",
    "\n",
    "Access to reading and pulling is controlled by the registry’s assigned keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "029d0610-92b5-4433-a432-02c7384f54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiolirest.models.autoscaling import Autoscaling\n",
    "from aiolirest.models.deployment_request import DeploymentRequest\n",
    "from aiolirest.models.security import Security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d823d1df-a75e-4a47-93a2-2e4ae248246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = aiolirest.DeploymentsApi(restclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "931e6c9c-3ede-4cec-a6cc-559feca60a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "config = {\n",
    "    'autoscaling_target': 1,\n",
    "    'autoscaling_metric': 'rps',\n",
    "    'autoscaling_max_replicas': 1,\n",
    "    'autoscaling_min_replicas': 1,\n",
    "}\n",
    "args = Namespace(**config)\n",
    "sec = Security(authenticationRequired=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73086da1-b070-42ad-9b2e-d91d991d9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = Autoscaling(\n",
    "    metric=args.autoscaling_metric,\n",
    ")\n",
    "\n",
    "if args.autoscaling_target is not None:\n",
    "    auto.target = args.autoscaling_target\n",
    "\n",
    "if args.autoscaling_max_replicas is not None:\n",
    "    auto.max_replicas = args.autoscaling_max_replicas\n",
    "\n",
    "if args.autoscaling_min_replicas is not None:\n",
    "    auto.min_replicas = args.autoscaling_min_replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4c3ebc0-aadf-41a9-a622-2354ffd7e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = DeploymentRequest(\n",
    "    name='deployment-from-sdk',\n",
    "    model=resposne.name,\n",
    "    security=sec,\n",
    "    namespace=namespace,\n",
    "    autoScaling=auto,\n",
    ")\n",
    "results = api_instance.deployments_post(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5932f6b7-c628-4310-953a-3a5e59539af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deployment(arguments=None, auto_scaling=Autoscaling(max_replicas=1, metric='rps', min_replicas=1, target=1), canary_traffic_percent=100, cluster_name='', environment={}, goal_status='Ready', id='5c5da1e5-ddfa-477b-899c-173263ec853d', last_event=None, model='15c0b7a3-062a-4959-ae6c-8f3321bd24b2', modified_at='2025-11-14T15:01:07.321965Z', name='deployment-from-sdk', namespace='geun-tak-roh-hp-b3801707', node_selectors={}, priority_class_name='', project='69fc1dd6-47eb-4411-9d75-dc24d94db622', secondary_state=DeploymentState(endpoint='', failure_info=None, mdl_id='', native_app_name='', status='None', traffic_percentage=0), security=Security(authentication_required=True), state=DeploymentState(endpoint='', failure_info=None, mdl_id='', native_app_name='', status='Deploying', traffic_percentage=0), status='Deploying')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2499f2d-7fbb-4c42-87d9-24061651f0c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Model is Ready!\n"
     ]
    }
   ],
   "source": [
    "from aioli.cli import deployment\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    print(deployment.lookup_deployment(results.name,api_instance).status)\n",
    "    time.sleep(5)\n",
    "    if deployment.lookup_deployment(results.name,api_instance).status == 'Ready':\n",
    "        print(\"Model is Ready!\")\n",
    "        break\n",
    "    elif deployment.lookup_deployment(results.name,api_instance).status != 'Deploying':\n",
    "        print('Something went wrong, Check the deployment!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa111a3-b213-4860-a682-c9a15ad0c595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://deployment-from-sdk-predictor-geun-tak-roh-hp-b3801707.app.pcai.sgctc.net'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment.lookup_deployment(results.name,api_instance).state.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a55e967e-eedb-4449-ae47-8c88faafdf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'deployment-from-sdk-predictor-geun-tak-roh-hp-b3801707.app.pcai.sgctc.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'deployment-from-sdk-predictor-geun-tak-roh-hp-b3801707.app.pcai.sgctc.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceTB/SmolLM2-360M-Instruct\n",
      "*** HuggingFaceTB/SmolLM2-360M-Instruct ***\n",
      "To solve this problem, let's first understand the given information: Mark was playing for 20 minutes, then rested, and then played for another 35 minutes.\n",
      "\n",
      "Step 1: Calculate Mark's rest period.\n",
      "Mark rested after 20 minutes, so let's subtract 20 from the total duration of the soccer game to find the rest period. \n",
      "\n",
      "90 minutes - 20 minutes (rest) = 70 minutes\n",
      "\n",
      "Step 2: Calculate Mark's playtime.\n",
      "Mark is being paid an hourly wage of $20. His playtime is the number of minutes worked after he rested.\n",
      "\n",
      "Mark worked for 70 minutes after he rested, so let's subtract 70 minutes from the total time to find the playtime.\n",
      "\n",
      "90 minutes - 70 minutes (rest) = 20 minutes\n",
      "\n",
      "Step 3: Calculate Mark's playtime.\n",
      "Now that we know Mark worked for 20 minutes, we can subtract it from the total duration of the soccer game to find the time he played.\n",
      "\n",
      "In 20 minutes, Mark played for 90 - 20 minutes = 70 minutes.\n",
      "\n",
      "Step 4: Calculate Mark's time on the sideline.\n",
      "Since Mark played for 70 minutes, we can multiply this by Mark's hourly wage to find the time he played on the sideline.\n",
      "\n",
      "Mark worked for 70 minutes, and since he made $20 per hour, he earned $20 * 70 minutes = $1400.\n",
      "\n",
      "Step 5: Find the time Mark played on the sideline.\n",
      "Now that we know Mark played for 70 minutes, we can multiply this by the number of minutes he played, as we are finding the time he played on the sideline.\n",
      "\n",
      "It can be assumed that Mark played for another 35 minutes after he rested, but we are only interested in his time on the sideline during that length. Therefore, we will calculate Mark's playtime on the sideline.\n",
      "\n",
      "We know Mark played for 20 minutes in the first part of the soccer game. Then, he rested for 35 minutes, so his playtime on the sideline is 20 minutes (played in the first part) + 35 minutes (rested) = 37 minutes.\n",
      "\n",
      "Step 6: Determine the answer.\n",
      "Since Mark played for 70 minutes and there are 60 minutes in 1 hour, we can divide Mark's playtime on the sideline (37 minutes) by his playtime (60 minutes) to find the length of his sideline time.\n",
      "\n",
      "37 minutes / 60 minutes = 0.65 hours.\n",
      "\n",
      "Therefore, Mark played for 0.65 hours on the sideline.\n",
      "math-lora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'deployment-from-sdk-predictor-geun-tak-roh-hp-b3801707.app.pcai.sgctc.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** math-lora ***\n",
      "Mark played for a total of 20 + 35 = 55 minutes. Now, he rested for 90 minutes - 55 minutes = 35 minutes. So, he was rested for 55 minutes / 35 minutes = 1.667 hours (since 1 hour is equal to 3600 seconds).\n",
      "\n",
      "Now, Mark is rested for x minutes. Let's solve for x:\n",
      "x = 550 seconds / x = (550 seconds / 60 seconds per minute) = 9.167 minutes.\n",
      "\n",
      "So, Mark was rested for approximately 9.167 minutes or 1.667 hours.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open('/etc/secrets/ezua/.auth_token','r') as file:\n",
    "    AUTH_TOKEN = file.read()\n",
    "endpoint_url = deployment.lookup_deployment(results.name,api_instance).state.endpoint\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {AUTH_TOKEN}\"\n",
    "}\n",
    "\n",
    "route = '/v1/models'\n",
    "models_response = requests.get(endpoint_url+route,headers=headers,verify=False)\n",
    "sample_prompt = \"In a 90-minute soccer game, Mark played 20 minutes, then rested after. He then played for another 35 minutes. How long was he on the sideline?\"\n",
    "\n",
    "for model in models_response.json()['data']:\n",
    "    print(model['id'])\n",
    "    payload = {\n",
    "        \"model\": model['id'],\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"you are a helpful math tutor, solve the question step by step\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sample_prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    route = '/v1/chat/completions'\n",
    "    chat_response = requests.post(endpoint_url+route,headers=headers,verify=False,json=payload)\n",
    "    print(f\"*** {model['id']} ***\\n{chat_response.json()['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b603f0b-4f18-470f-bee7-ef4ced6a6d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

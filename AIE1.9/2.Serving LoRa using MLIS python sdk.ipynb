{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbd32dc-ed65-4f5a-b1d8-be620c78089c",
   "metadata": {},
   "source": [
    "# PCAI Use Case Demo - Serving LoRa in MLIS\n",
    "In this tutorial, we will deploy LoRa Adapter with vLLM in MLIS. Additionally, we will leverage aioli-sdk to programatically deploy the model in MLIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79724053-ed09-4fcd-9514-549ba75cd943",
   "metadata": {},
   "source": [
    "**1. Install Required Libraries**</br>\n",
    "Before running the demo, please install the necessary libraries in your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7864cc1f-b054-4b78-8d11-56b083a52fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aioli-sdk==1.10.0 in /opt/conda/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (24.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (1.26.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=18.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (27.0.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (3.20.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (2.32.4)\n",
      "Requirement already satisfied: lomond>=0.3.3 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (0.3.3)\n",
      "Requirement already satisfied: pathspec>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (0.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (3.2.0)\n",
      "Requirement already satisfied: argcomplete>=1.9.4 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (3.6.3)\n",
      "Requirement already satisfied: gitpython>=3.1.3 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (3.1.45)\n",
      "Requirement already satisfied: pyOpenSSL>=19.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (25.3.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (2025.2)\n",
      "Requirement already satisfied: tabulate>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (0.9.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.15.29 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (0.18.14)\n",
      "Requirement already satisfied: docker>=3.7.3 in /opt/conda/lib/python3.11/site-packages (from docker[ssh]>=3.7.3->aioli-sdk==1.10.0) (7.1.0)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (4.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (4.67.1)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (1.4.4)\n",
      "Requirement already satisfied: analytics-python in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (1.4.post1)\n",
      "Requirement already satisfied: urllib3<2.3.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (2.2.3)\n",
      "Requirement already satisfied: pydantic>=2 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.7.1 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (4.14.1)\n",
      "Requirement already satisfied: pytest>=7.4.4 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (9.0.1)\n",
      "Requirement already satisfied: pytest-cov>=4.1.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (7.0.0)\n",
      "Requirement already satisfied: pexpect>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from aioli-sdk==1.10.0) (4.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython>=3.1.3->aioli-sdk==1.10.0) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.3->aioli-sdk==1.10.0) (5.0.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from lomond>=0.3.3->aioli-sdk==1.10.0) (1.17.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.10.0) (5.0.0)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.10.0) (46.0.3)\n",
      "Requirement already satisfied: invoke>=2.0 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.10.0) (2.2.1)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.11/site-packages (from paramiko>=2.4.2->aioli-sdk==1.10.0) (1.6.1)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.3->paramiko>=2.4.2->aioli-sdk==1.10.0) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=3.3->paramiko>=2.4.2->aioli-sdk==1.10.0) (2.22)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>=4.9.0->aioli-sdk==1.10.0) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2->aioli-sdk==1.10.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2->aioli-sdk==1.10.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2->aioli-sdk==1.10.0) (0.4.1)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from pytest>=7.4.4->aioli-sdk==1.10.0) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.11/site-packages (from pytest>=7.4.4->aioli-sdk==1.10.0) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /opt/conda/lib/python3.11/site-packages (from pytest>=7.4.4->aioli-sdk==1.10.0) (2.19.2)\n",
      "Requirement already satisfied: coverage>=7.10.6 in /opt/conda/lib/python3.11/site-packages (from coverage[toml]>=7.10.6->pytest-cov>=4.1.0->aioli-sdk==1.10.0) (7.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->aioli-sdk==1.10.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->aioli-sdk==1.10.0) (3.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.11/site-packages (from ruamel.yaml>=0.15.29->aioli-sdk==1.10.0) (0.2.8)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.11/site-packages (from analytics-python->aioli-sdk==1.10.0) (1.6)\n",
      "Requirement already satisfied: backoff==1.10.0 in /opt/conda/lib/python3.11/site-packages (from analytics-python->aioli-sdk==1.10.0) (1.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install aioli-sdk==1.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c4a0a-c2b6-40da-9100-49450f9080cd",
   "metadata": {},
   "source": [
    "# Intialize API client for MLIS's rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca9d23b-c70d-461a-b1aa-20cbfdd2c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = os.popen(\"kubectl get pvc user-pvc -o=jsonpath='{.metadata.namespace}'\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96119976-ef2a-4562-b363-ed10cc7ea8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiolirest\n",
    "from aioli.common import util\n",
    "from aioli.common.api import authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb44a94-9483-455b-bbe3-1c8bb9774d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_url = \"http://aioli-master-service-hpe-mlis.mlis.svc.cluster.local:8080\"\n",
    "\n",
    "host = util.prepend_protocol(host_url)\n",
    "token = util.get_aioli_user_token_from_env()\n",
    "configuration = authentication.get_rest_config(host)\n",
    "configuration.api_key[\"ApiKeyAuth\"] = \"Bearer \" + token\n",
    "restclient = aiolirest.ApiClient(configuration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4cfaebc-9d76-4b71-b121-cadb6f552496",
   "metadata": {},
   "source": [
    "# Create Registry\n",
    "In MLIS, Registries are the storage location of the models. User can ADD/EDIT/LIST/DELETE Registry\n",
    "**Available Registry Types**\n",
    "- S3 : S3 bucket and necessary Access keys needed\n",
    "- Huggingface or OpenLLM : Sign up for a HuggingFace and create an access token\n",
    "- NGC : Sign up for an NVIDIA NGC Account and obtain the necessary API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845d1cff-cec8-4889-9627-2c792fdd9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = aiolirest.RegistriesApi(restclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c65bf3e-317d-4591-967c-e8468b3833bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found endpoint for s3 via: environment_global.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow.aie01\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3 = boto3.client(\"s3\", verify=False)\n",
    "buckets = s3.list_buckets()\n",
    "for bucket in buckets['Buckets']:\n",
    "    if 'mlflow' in bucket['Name']:\n",
    "      bucket_name = bucket['Name']\n",
    "\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbed04e2-dd99-4c71-bfbd-b2264d0779ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiolirest.models.trained_model_registry_request import TrainedModelRegistryRequest\n",
    "\n",
    "r = TrainedModelRegistryRequest(\n",
    "    name='s3-bucket-from-sdk',\n",
    "    bucket=bucket_name,\n",
    "    endpointUrl='http://local-s3-service.ezdata-system.svc.cluster.local:30000',\n",
    "    type='s3',\n",
    "    accessKey=None,\n",
    "    secretKey='',\n",
    "    insecureHttps=False,\n",
    ")\n",
    "registry_request = api_instance.registries_post(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4777c972-e098-400f-9954-6b4fde963cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainedModelRegistry(access_key='', bucket='mlflow.aie01', endpoint_url='http://local-s3-service.ezdata-system.svc.cluster.local:30000', id='b86fbfef-0d03-4f3a-bc20-a00c17084bf0', insecure_https=False, modified_at='2025-11-16T15:07:34.648359508Z', name='s3-bucket-from-sdk', project='', secret_key='', type='s3')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry_request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926b828-bc59-460e-b614-3e57faf7dfd8",
   "metadata": {},
   "source": [
    "<img src=\"../assets/mlis_registry_1.png\" alt=\"mlis_registry_1\" width=\"400\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a9a2cd-fbb5-4af5-a33b-538fe9c87247",
   "metadata": {},
   "source": [
    "# Create Packaged Model\n",
    "In MLIS, A packaged Model describes the model that user want to deploy as an inference service.\n",
    "By Adding a packaged model, user can create a versioned pointer to a model stored in a specified registry and PVC. \n",
    "Access to reading and pulling is controlled by the registry’s assigned keys\n",
    "\n",
    "**Available Model Types**\n",
    "- Bento Archive : S3\n",
    "- Custom : OpenLLM, PVC, S3, None\n",
    "- NIM : NGC, PVC\n",
    "- OpenLLM : OpenLLM, S3\n",
    "- vLLM : HuggingFace, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0670439a-3486-4d82-9a26-2ce8b5dc42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiolirest.models.configuration_resources import ConfigurationResources\n",
    "from aiolirest.models.packaged_model_request import PackagedModelRequest\n",
    "from aiolirest.models.resource_profile import ResourceProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d1690d-dc2e-4192-a0d5-9e64834624cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = aiolirest.PackagedModelsApi(restclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dc1d328-1458-46ca-a47a-8cf5663cbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "full_model_name = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "\n",
    "config = {\n",
    "    'requests_cpu': '1',\n",
    "    'requests_gpu': '1',\n",
    "    'requests_memory': '4Gi',\n",
    "    'limits_cpu': '4',\n",
    "    'limits_gpu': '1',\n",
    "    'limits_memory': '8Gi',\n",
    "    'enable_caching': False,\n",
    "    'disable_caching': False,\n",
    "    'metadata': {\n",
    "        'modelCategory=llm'\n",
    "    },\n",
    "    'env': {},\n",
    "    'arg': [\n",
    "        '--model',\n",
    "        full_model_name,\n",
    "        '--port',\n",
    "        '8080',\n",
    "        '--dtype=half',\n",
    "        '--gpu-memory-utilization',\n",
    "        '0.8',\n",
    "        '--enable-lora',\n",
    "        '--lora-modules',\n",
    "        '{\"name\":\"math-lora\",\"path\":\"/mnt/models\",\"base_model_name\":\"' + full_model_name + '\"}',\n",
    "    ]\n",
    "}\n",
    "args = Namespace(**config)\n",
    "requests = ResourceProfile(\n",
    "    cpu=args.requests_cpu, gpu=args.requests_gpu, memory=args.requests_memory\n",
    ")\n",
    "limits = ResourceProfile(\n",
    "    cpu=args.limits_cpu, gpu=args.limits_gpu, memory=args.limits_memory\n",
    ")\n",
    "resources = ConfigurationResources(gpuType=None, requests=requests, limits=limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c3a372-8b8b-4f19-9cd0-22d68bf9358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelCategory': 'llm'}\n",
      "{}\n",
      "['--model', 'HuggingFaceTB/SmolLM2-360M-Instruct', '--port', '8080', '--dtype=half', '--gpu-memory-utilization', '0.8', '--enable-lora', '--lora-modules', '{\"name\":\"math-lora\",\"path\":\"/mnt/models\",\"base_model_name\":\"HuggingFaceTB/SmolLM2-360M-Instruct\"}']\n"
     ]
    }
   ],
   "source": [
    "from aioli.common.util import (\n",
    "    construct_arguments,\n",
    "    construct_environment,\n",
    "    construct_metadata,\n",
    ")\n",
    "print(construct_metadata(args, {}))\n",
    "print(construct_environment(args))\n",
    "print(construct_arguments(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "089d7801-f0ab-41fc-b2ab-030cab6c2d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact URI: s3://mlflow.aie01/0/c95a898568c14429917e9c6adad98400/artifacts\n",
      "Full artifact URI: s3://mlflow.aie01/0/c95a898568c14429917e9c6adad98400/artifacts/math-SmolLM2-360M-Instruct-savedir/peft\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Get the experiment ID\n",
    "experiment_name = \"Default\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "latest_run = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "artifact_uri = latest_run.artifact_uri[0]\n",
    "print(f\"Artifact URI: {artifact_uri}\")\n",
    "\n",
    "# For a specific artifact file/folder\n",
    "artifact_path = 'math-SmolLM2-360M-Instruct-savedir/peft'  # or any artifact path\n",
    "\n",
    "full_artifact_uri = f\"{artifact_uri}/{artifact_path}\"\n",
    "print(f\"Full artifact URI: {full_artifact_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8d5f817-661a-4c80-8062-d7036db1d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = PackagedModelRequest(\n",
    "    name='packaged-model-from-sdk',\n",
    "    description='packaged-model-from-sdk',\n",
    "    url=full_artifact_uri,\n",
    "    # url='s3://mlflow.aie01/2/1fc4eae4cb9f43928f5455a587add06b/artifacts/SmolLM2-360M-Instruct-savedir/peft',\n",
    "    image='vllm/vllm-openai:v0.8.5',\n",
    "    resources=resources,\n",
    "    modelFormat='custom',\n",
    "    arguments=construct_arguments(args),\n",
    "    metadata=construct_metadata(args, {}),\n",
    "    registry=registry_request.name,\n",
    ")\n",
    "\n",
    "if args.enable_caching:\n",
    "    r.caching_enabled = True\n",
    "\n",
    "if args.disable_caching:\n",
    "    r.caching_enabled = False\n",
    "\n",
    "resposne = api_instance.models_post(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa5b4a13-84bb-4912-813c-402404c34b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackagedModel(arguments=['--model', 'HuggingFaceTB/SmolLM2-360M-Instruct', '--port', '8080', '--dtype=half', '--gpu-memory-utilization', '0.8', '--enable-lora', '--lora-modules', '{\"name\":\"math-lora\",\"path\":\"/mnt/models\",\"base_model_name\":\"HuggingFaceTB/SmolLM2-360M-Instruct\"}'], caching_enabled=False, description='packaged-model-from-sdk', environment={}, id='7b74bb6a-7fff-46c2-a31c-e6329539ddda', image='vllm/vllm-openai:v0.8.5', metadata={'modelCategory': 'llm'}, format='custom', modified_at='2025-11-16T15:08:57.951195Z', name='packaged-model-from-sdk', project='', registry='b86fbfef-0d03-4f3a-bc20-a00c17084bf0', resources=ConfigurationResources(gpu_type='', limits=ResourceProfile(cpu='4', gpu='1', memory='8Gi'), requests=ResourceProfile(cpu='1', gpu='1', memory='4Gi')), url='s3://mlflow.aie01/0/c95a898568c14429917e9c6adad98400/artifacts/math-SmolLM2-360M-Instruct-savedir/peft', version=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75266c-4d7d-47ea-bcb7-e61a0d1b1e6c",
   "metadata": {},
   "source": [
    "<img src=\"../assets/mlis_packaged_1.png\" alt=\"mlis_packaged_1\" width=\"400\">\n",
    "<img src=\"../assets/mlis_packaged_2.png\" alt=\"mlis_packaged_2\" width=\"400\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a9b4888-121e-4923-9e05-b8a3b148b402",
   "metadata": {},
   "source": [
    "# Deploy Model\n",
    "In MLIS, Deployments spin up the actual instances that run user’s inference services. \n",
    "\n",
    "As a result of deployment, it will provide an endpoint that can be used by clients to make predictions.\n",
    "\n",
    "Access to reading and pulling is controlled by the registry’s assigned keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "029d0610-92b5-4433-a432-02c7384f54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiolirest.models.autoscaling import Autoscaling\n",
    "from aiolirest.models.deployment_request import DeploymentRequest\n",
    "from aiolirest.models.security import Security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d823d1df-a75e-4a47-93a2-2e4ae248246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = aiolirest.DeploymentsApi(restclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "931e6c9c-3ede-4cec-a6cc-559feca60a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "config = {\n",
    "    'autoscaling_target': 1,\n",
    "    'autoscaling_metric': 'rps',\n",
    "    'autoscaling_max_replicas': 1,\n",
    "    'autoscaling_min_replicas': 1,\n",
    "}\n",
    "args = Namespace(**config)\n",
    "sec = Security(authenticationRequired=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73086da1-b070-42ad-9b2e-d91d991d9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = Autoscaling(\n",
    "    metric=args.autoscaling_metric,\n",
    ")\n",
    "\n",
    "if args.autoscaling_target is not None:\n",
    "    auto.target = args.autoscaling_target\n",
    "\n",
    "if args.autoscaling_max_replicas is not None:\n",
    "    auto.max_replicas = args.autoscaling_max_replicas\n",
    "\n",
    "if args.autoscaling_min_replicas is not None:\n",
    "    auto.min_replicas = args.autoscaling_min_replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4c3ebc0-aadf-41a9-a622-2354ffd7e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = DeploymentRequest(\n",
    "    name='deployment-from-sdk',\n",
    "    model=resposne.name,\n",
    "    security=sec,\n",
    "    namespace=namespace,\n",
    "    autoScaling=auto,\n",
    ")\n",
    "results = api_instance.deployments_post(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5932f6b7-c628-4310-953a-3a5e59539af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deployment(arguments=None, auto_scaling=Autoscaling(max_replicas=1, metric='rps', min_replicas=1, target=1), canary_traffic_percent=100, cluster_name='', environment={}, goal_status='Ready', id='4f3305a0-adc0-4a24-9495-89e4c02f5fd8', last_event=None, model='7b74bb6a-7fff-46c2-a31c-e6329539ddda', modified_at='2025-11-16T15:09:25.917722Z', name='deployment-from-sdk', namespace='project-user-geun-tak-roh', node_selectors={}, priority_class_name='', project='', secondary_state=DeploymentState(endpoint='', failure_info=None, mdl_id='', native_app_name='', status='None', traffic_percentage=0), security=Security(authentication_required=True), state=DeploymentState(endpoint='', failure_info=None, mdl_id='', native_app_name='', status='Deploying', traffic_percentage=0), status='Deploying')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2499f2d-7fbb-4c42-87d9-24061651f0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Deploying\n",
      "Model is Ready!\n"
     ]
    }
   ],
   "source": [
    "from aioli.cli import deployment\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    print(deployment.lookup_deployment(results.name,api_instance).status)\n",
    "    time.sleep(5)\n",
    "    if deployment.lookup_deployment(results.name,api_instance).status == 'Ready':\n",
    "        print(\"Model is Ready!\")\n",
    "        break\n",
    "    elif deployment.lookup_deployment(results.name,api_instance).status != 'Deploying':\n",
    "        print('Something went wrong, Check the deployment!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5aa111a3-b213-4860-a682-c9a15ad0c595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://deployment-from-sdk.project-user-geun-tak-roh.serving.aie01.pcai.tryezmeral.com'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment.lookup_deployment(results.name,api_instance).state.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a55e967e-eedb-4449-ae47-8c88faafdf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geun-tak-roh/.conda/envs/finetune/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'deployment-from-sdk.project-user-geun-tak-roh.serving.aie01.pcai.tryezmeral.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/geun-tak-roh/.conda/envs/finetune/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'deployment-from-sdk.project-user-geun-tak-roh.serving.aie01.pcai.tryezmeral.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceTB/SmolLM2-360M-Instruct\n",
      "*** HuggingFaceTB/SmolLM2-360M-Instruct ***\n",
      "To find out how long Mark was on the sideline, we need to know the duration between his consecutive starts. Let's first determine the first start.\n",
      "\n",
      "During Mark's first 20 minutes, he would have had 20 minutes of rest. Since he had to continue gameplay for another 35 minutes, the time between his last start to the second start must be 90 - 55 = 35 minutes.\n",
      "\n",
      "Now, let's solve the remaining part of the equation. We know Mark started his second 35-minute period with the idea of an ongoing game. Thus, he actually played for 35 minutes in total, but then quit after one more play, which is equivalent to 20 minutes (35 - 55).\n",
      "\n",
      "We can infer this by focusing on the duration he actually played during his two 35-minute periods. If Mark had 20 minutes of rest and 35 minutes in action, this means he took 20 + 35 = 55 minutes off the actual section he played out the first time, and thus the whole objective phase of a game would have been 35, since the rest of the game was continuous.\n",
      "\n",
      "So, Mark's second 35-minute period, which was the rest time, was 35 more than the original 55-minute continuous action he took. Therefore, the time Mark spent on the sideline after at least one rest period and during any subsequent crazy rush is still 35 more minutes than that being this period.\n",
      "math-lora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geun-tak-roh/.conda/envs/finetune/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'deployment-from-sdk.project-user-geun-tak-roh.serving.aie01.pcai.tryezmeral.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** math-lora ***\n",
      "First, we need to find the time Mark played. He played for 20 minutes and rested after. So, he played 20 - 20 = 0 minutes.\n",
      "\n",
      "Next, we need to find the total time his teammates played, given that Mark rested. There are 20 minutes in 90 minutes. So, the total time his teammates played before Mark rested is 90 minutes / 20 minutes per minute = 4.5 minutes. After Mark rested, the total time his teammates played before him is 1 - 0 = 0 minutes.\n",
      "\n",
      "Now, we need to find the remaining time, before any regular football play, that Mark played.\n",
      "\n",
      "Mark didn't play the whole 90 minutes. We found out that he played 0 minutes before rest. Let's call this time t.\n",
      "\n",
      "Since he played 0 minutes after rest, he must have finished the entire 90 minutes before rest. This means he played 90 - t minutes.\n",
      "\n",
      "We know that the total time he played before Mark rested is 4.5 minutes. So, we can write the equation: 90 - t = 4.5.\n",
      "\n",
      "Now, we need to find the value of t, which represents his time playing before rest. We have an equation, but no number that we can solve for t automatically. Of course, we can do this manually or use numerical methods. However, if we still don't get an answer, we'd know that there is no solution for t.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open('/etc/secrets/ezua/.auth_token','r') as file:\n",
    "    AUTH_TOKEN = file.read()\n",
    "endpoint_url = deployment.lookup_deployment(results.name,api_instance).state.endpoint\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {AUTH_TOKEN}\"\n",
    "}\n",
    "\n",
    "route = '/v1/models'\n",
    "models_response = requests.get(endpoint_url+route,headers=headers,verify=False)\n",
    "sample_prompt = \"In a 90-minute soccer game, Mark played 20 minutes, then rested after. He then played for another 35 minutes. How long was he on the sideline?\"\n",
    "\n",
    "for model in models_response.json()['data']:\n",
    "    print(model['id'])\n",
    "    payload = {\n",
    "        \"model\": model['id'],\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"you are a helpful math tutor, solve the question step by step\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sample_prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    route = '/v1/chat/completions'\n",
    "    chat_response = requests.post(endpoint_url+route,headers=headers,verify=False,json=payload)\n",
    "    print(f\"*** {model['id']} ***\\n{chat_response.json()['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cb617-cb77-463f-a2f4-e798cc3dc924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
